{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a03b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "INPUT_DATASET = \"dataset/original\"\n",
    "BASE_PATH=\"datasets/idc\"\n",
    "TRAIN_PATH=os.path.sep.join([BASE_PATH,\"training\"])\n",
    "VAL_PATH=os.path.sep.join([BASE_PATH,\"validation\"])\n",
    "TEST_PATH=os.path.sep.join([BASE_PATH,\"testing\"])\n",
    "TRAIN_SPLIT=0.8\n",
    "VAL_SPLIT=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24dd0589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training set\n",
      "Building validation set\n",
      "Building testing set\n"
     ]
    }
   ],
   "source": [
    "from imutils import paths\n",
    "import random, shutil,os\n",
    "originalPaths = list(paths.list_images(INPUT_DATASET)) \n",
    "\n",
    "random.seed(7)\n",
    "random.shuffle(originalPaths)\n",
    "\n",
    "index = int(len(originalPaths) * TRAIN_SPLIT)\n",
    "trainPaths = originalPaths[:index]\n",
    "testPaths = originalPaths[index:]\n",
    "\n",
    "index = int(len(trainPaths) * VAL_SPLIT)\n",
    "valPaths = trainPaths[:index]\n",
    "trainPaths = trainPaths[index:]\n",
    "\n",
    "datasets = [\n",
    "    (\"training\", trainPaths, TRAIN_PATH),\n",
    "    (\"validation\", valPaths, VAL_PATH),\n",
    "    (\"testing\", testPaths, TEST_PATH),  \n",
    "]\n",
    "\n",
    "for (setType, originalPaths, basePath) in datasets:\n",
    "    print(f'Building {setType} set')\n",
    "    if not os.path.exists(basePath):\n",
    "        print(f'Building directory {basePath}')\n",
    "        os.makedirs(basePath)\n",
    "    for path in originalPaths:\n",
    "        file = path.split(os.path.sep)[-1]  \n",
    "        label = split[-5:-4] \n",
    "        labelPath = os.path.sep.join([basePath,label])\n",
    "        if not os.path.exists(labelPath):\n",
    "            print(f'Building directory {labelPath}')\n",
    "            os.makedirs(labelPath)\n",
    "        newPath = os.path.sep.join([labelPath, file])\n",
    "        shutil.copy2(path, newPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b14b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "\n",
    "class CancerNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        shape = (height, width, depth)\n",
    "        channelDim = -1  # Change channelDim from 1 to -1 for 'channels_last'\n",
    "        \n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            shape = (depth, height, width)\n",
    "            channelDim = 1\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=shape))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis=channelDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "    \n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4c2bcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 555048 images belonging to 284 classes.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./ 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\narhariyaligeti\\Documents\\ai ml\\ai ml\\project 2 breast cancer', \n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff52353a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m lenTest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(paths\u001b[38;5;241m.\u001b[39mlist_images(TEST_PATH)))\n\u001b[0;32m     22\u001b[0m trainLabels\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(p\u001b[38;5;241m.\u001b[39msplit(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m trainPaths] \n\u001b[1;32m---> 23\u001b[0m trainLabels \u001b[38;5;241m=\u001b[39mnp_utils(trainLabels)\n\u001b[0;32m     24\u001b[0m classTotals \u001b[38;5;241m=\u001b[39m trainLabel\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     25\u001b[0m classWeight \u001b[38;5;241m=\u001b[39m classTotals\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m/\u001b[39m classTotals\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from imutils import paths  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "TRAIN_PATH = 'path_to_training_directory'\n",
    "VAL_PATH = 'path_to_validation_directory'\n",
    "TEST_PATH = 'path_to_testing_directory'\n",
    "\n",
    "NUM_EPOCHS = 4\n",
    "INIT_LR = 1e-2  \n",
    "BS = 32\n",
    "\n",
    "trainPaths = list(paths.list_images(TRAIN_PATH))\n",
    "\n",
    "lenTrain = len(trainPaths)\n",
    "lenVal = len(list(paths.list_images(VAL_PATH)))\n",
    "lenTest = len(list(paths.list_images(TEST_PATH)))\n",
    "\n",
    "trainLabels= [int(p.split(os.path.sep)[-2]) for p in trainPaths] \n",
    "trainLabels =np_utils(trainLabels)\n",
    "classTotals = trainLabel.sum(axis=0)\n",
    "classWeight = classTotals.max() / classTotals\n",
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "    rescale=1 / 255.0,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.05,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=BS\n",
    ")\n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BS\n",
    ")\n",
    "\n",
    "testGen = valAug.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3416e609",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CancerNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m CancerNet\u001b[38;5;241m.\u001b[39mbuild(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m48\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m48\u001b[39m, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CancerNet' is not defined"
     ]
    }
   ],
   "source": [
    "model = CancerNet.build(width=48, height=48, depth=3, classes=2)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "710986b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainGen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m M\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mtrainGen, validation_data\u001b[38;5;241m=\u001b[39mvalGen, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainGen' is not defined"
     ]
    }
   ],
   "source": [
    "M=model.fit(x=trainGen, validation_data=valGen, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0b8fa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating the model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testGen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNow evaluating the model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m testGen\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      3\u001b[0m pred_indices\u001b[38;5;241m=\u001b[39mmode1\u001b[38;5;241m.\u001b[39mpredict_generator(testGen,steps\u001b[38;5;241m=\u001b[39m(lenTest\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBS)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m pred_indices\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(pred_indices,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testGen' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Now evaluating the model\")\n",
    "testGen.reset()\n",
    "pred_indices=mode1.predict_generator(testGen,steps=(lenTest//BS)+1)\n",
    "\n",
    "pred_indices=np.argmax(pred_indices,axis=1)\n",
    "\n",
    "print(classification_report(testGen.classes, pred_indices, target_names=testGen.class_indices.keys()))\n",
    "\n",
    "cm=confusion_matrix(testGen.classes,pred_indices)\n",
    "total=sum(sum(cm))\n",
    "accuracy=(cm[0,0]+cm[1,1])/total\n",
    "specificity=cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print(cm)\n",
    "print(f'Accuracy:{accuracy}')\n",
    "print(f'Specificity:{specifity}')\n",
    "print(f'Sensitivity:{sensitivity}')\n",
    "\n",
    "N=NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arrange(0,N),M.history[\"loss\"],label=\"train_loss\")\n",
    "plt.plot(np.arrange(0,N),M.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.plot(np.arrange(0,N),M.history[\"acc\"],label=\"train_acc\")\n",
    "plt.plot(np.arrange(0,N),M.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.title(\"Training Loss and Accuracy on the IDC Dataset\")\n",
    "plt.xlabel(\"Epoch No.\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rom keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imutils import paths  # Fix import statement: 'import imutils import paths'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# You need to define TRAIN_PATH, VAL_PATH, and TEST_PATH here\n",
    "\n",
    "NUM_EPOCHS = 4\n",
    "INIT_LR = 1e-2  # Changed 'len-2' to '1e-2'\n",
    "BS = 32\n",
    "\n",
    "trainPaths = list(paths.list_images(TRAIN_PATH))\n",
    "lenTrain = len(trainPaths)\n",
    "lenVal = len(list(paths.list_images(VAL_PATH)))\n",
    "lenTest = len(list(paths.list_images(TEST_PATH)))\n",
    "\n",
    "trainLabels = [int(p.split(os.path.sep)[-2]) for p in trainPaths]  # Fixed syntax error\n",
    "trainLabel = np_utils.to_categorical(trainLabels)\n",
    "classTotals = trainLabel.sum(axis=0)\n",
    "classWeight = classTotals.max() / classTotals\n",
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "    rescale=1 / 255.0,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.05,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,  # Changed 'vertical_flips' to 'vertical_flip'\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=BS\n",
    ")\n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BS  # Fixed a syntax error: removed extra closing parenthesis\n",
    ")\n",
    "\n",
    "testGen = valAug.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BS  # Fixed a syntax error: removed extra closing parenthesis\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
